{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNVwIosoBke4",
        "outputId": "04be7823-4528-4c74-d833-d9b93ea17b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.3.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading jaxtyping-0.3.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, torchinfo, jaxtyping\n",
            "Successfully installed jaxtyping-0.3.3 torchinfo-1.8.0 wadler-lindig-0.1.7\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-4.4.1 pyarrow-22.0.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    %pip install torchinfo jaxtyping einops datasets\n",
        "    %pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import Literal\n",
        "\n",
        "import einops\n",
        "import torch as t\n",
        "from torch.nn import BatchNorm2d, Conv2d, Linear, ReLU, Sequential, ConvTranspose2d\n",
        "import torchinfo\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from einops.layers.torch import Rearrange\n",
        "from jaxtyping import Float, Int\n",
        "from torch import Tensor, nn\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = t.device(\n",
        "    \"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
        ")"
      ],
      "metadata": {
        "id": "vngUl_UHBryd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset() -> Dataset:\n",
        "    image_size = 64\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.CenterCrop(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]\n",
        "    )\n",
        "    trainset = datasets.CelebA(\n",
        "        root=\"./data\",\n",
        "        split=\"train\",\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    return trainset"
      ],
      "metadata": {
        "id": "3Lyxk3glCSLe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return (t.exp(x) - t.exp(-x)) / (t.exp(x) + t.exp(-x))\n",
        "\n",
        "\n",
        "class LeakyReLU(nn.Module):\n",
        "    def __init__(self, negative_slope: float = 0.01):\n",
        "        super().__init__()\n",
        "        self.negative_slope = negative_slope\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return t.where(x > 0, x, self.negative_slope * x)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"negative_slope={self.negative_slope}\"\n",
        "\n",
        "\n",
        "class Sigmoid(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return 1 / (1 + t.exp(-x))"
      ],
      "metadata": {
        "id": "QyhfvkAUC0iL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim_size: int = 100,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the generator architecture from the DCGAN paper (the diagram at the top\n",
        "        of page 4). We assume the size of the activations doubles at each layer (so image\n",
        "        size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            latent_dim_size:\n",
        "                the size of the latent dimension, i.e. the input to the generator\n",
        "            img_size:\n",
        "                the size of the image, i.e. the output of the generator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the generator (starting closest\n",
        "                to the middle of the DCGAN and going outward, i.e. in chronological order for\n",
        "                the generator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        hidden_channels = hidden_channels[::-1]\n",
        "        n_layers = len(hidden_channels)\n",
        "\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        height = img_size // 2 ** n_layers\n",
        "        size = hidden_channels[0] * height**2\n",
        "\n",
        "        self.project_and_reshape = Sequential(\n",
        "            Linear(latent_dim_size, size, bias=False),\n",
        "            Rearrange('b (c h w) -> b c h w', h=height, w=height),\n",
        "            BatchNorm2d(hidden_channels[0]),\n",
        "            ReLU(),\n",
        "        )\n",
        "\n",
        "        in_channels = hidden_channels\n",
        "        out_channels = hidden_channels[1:] + [img_channels]\n",
        "\n",
        "        conv_layers = []\n",
        "        for idx, (i, o) in enumerate(zip(in_channels, out_channels[:-1])):\n",
        "          conv_layers += [\n",
        "              ConvTranspose2d(i, o, 4, 2, 1),\n",
        "              BatchNorm2d(o),\n",
        "              ReLU(),\n",
        "          ]\n",
        "\n",
        "        conv_layers += [\n",
        "            ConvTranspose2d(in_channels[-1], out_channels[-1], 4, 2, 1),\n",
        "            Tanh(),\n",
        "        ]\n",
        "\n",
        "        self.hidden_layers = Sequential(*conv_layers)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.project_and_reshape(x)\n",
        "        x = self.hidden_layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the discriminator architecture from the DCGAN paper (the mirror image of\n",
        "        the diagram at the top of page 4). We assume the size of the activations doubles at\n",
        "        each layer (so image size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            img_size:\n",
        "                the size of the image, i.e. the input of the discriminator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the discriminator (starting\n",
        "                closest to the middle of the DCGAN and going outward, i.e. in reverse-\n",
        "                chronological order for the discriminator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "        n_layers = len(hidden_channels)\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        in_channels = [img_channels] + hidden_channels[:-1]\n",
        "        out_channels = hidden_channels\n",
        "\n",
        "        conv_layers = []\n",
        "        for idx, (i, o) in enumerate(zip(in_channels, out_channels)):\n",
        "          conv_layers.append(Conv2d(i, o, kernel_size=4, stride=2, padding=1)),\n",
        "          if (idx != 0):\n",
        "            conv_layers.append(BatchNorm2d(o))\n",
        "\n",
        "          conv_layers.append(LeakyReLU(0.2))\n",
        "\n",
        "        self.hidden_layers = Sequential(*conv_layers)\n",
        "\n",
        "        final_height = img_size // (2**n_layers)\n",
        "        final_size = hidden_channels[-1] * (final_height**2)\n",
        "        self.classifier = Sequential(\n",
        "            Rearrange('b c h w -> b (c h w)'),\n",
        "            Linear(final_size, 1, bias=False),\n",
        "            # Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.hidden_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.squeeze()  # remove dummy `out_channels` dimension\n",
        "\n",
        "class DCGAN(nn.Module):\n",
        "    netD: Discriminator\n",
        "    netG: Generator\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim_size: int = 100,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.netD = Discriminator(img_size, img_channels, hidden_channels)\n",
        "        self.netG = Generator(latent_dim_size, img_size, img_channels, hidden_channels)"
      ],
      "metadata": {
        "id": "Scw7TE0CC2hF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Initializes weights according to the DCGAN paper (details at the end of page 3 of the DCGAN\n",
        "    paper), by modifying the weights of the model in place.\n",
        "    \"\"\"\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, (ConvTranspose2d, Conv2d, Linear)):\n",
        "            nn.init.normal_(module.weight.data, 0.0, 0.02)\n",
        "        elif isinstance(module, BatchNorm2d):\n",
        "            nn.init.normal_(module.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(module.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "kmPRMnV0EOAK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DCGAN().to(device)\n",
        "x = t.randn(3, 100).to(device)\n",
        "print(torchinfo.summary(model.netG, input_data=x), end=\"\\n\\n\")\n",
        "print(torchinfo.summary(model.netD, input_data=model.netG(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDkBweU0EQoE",
        "outputId": "2845a7c4-6885-449c-c094-c64666abcf59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "Generator                                [3, 3, 64, 64]            --\n",
            "├─Sequential: 1-1                        [3, 512, 8, 8]            --\n",
            "│    └─Linear: 2-1                       [3, 32768]                3,276,800\n",
            "│    └─Rearrange: 2-2                    [3, 512, 8, 8]            --\n",
            "│    └─BatchNorm2d: 2-3                  [3, 512, 8, 8]            1,024\n",
            "│    └─ReLU: 2-4                         [3, 512, 8, 8]            --\n",
            "├─Sequential: 1-2                        [3, 3, 64, 64]            --\n",
            "│    └─ConvTranspose2d: 2-5              [3, 256, 16, 16]          2,097,408\n",
            "│    └─BatchNorm2d: 2-6                  [3, 256, 16, 16]          512\n",
            "│    └─ReLU: 2-7                         [3, 256, 16, 16]          --\n",
            "│    └─ConvTranspose2d: 2-8              [3, 128, 32, 32]          524,416\n",
            "│    └─BatchNorm2d: 2-9                  [3, 128, 32, 32]          256\n",
            "│    └─ReLU: 2-10                        [3, 128, 32, 32]          --\n",
            "│    └─ConvTranspose2d: 2-11             [3, 3, 64, 64]            6,147\n",
            "│    └─Tanh: 2-12                        [3, 3, 64, 64]            --\n",
            "==========================================================================================\n",
            "Total params: 5,906,563\n",
            "Trainable params: 5,906,563\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 3.31\n",
            "==========================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 11.30\n",
            "Params size (MB): 23.63\n",
            "Estimated Total Size (MB): 34.93\n",
            "==========================================================================================\n",
            "\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "Discriminator                            [3]                       --\n",
            "├─Sequential: 1-1                        [3, 512, 8, 8]            --\n",
            "│    └─Conv2d: 2-1                       [3, 128, 32, 32]          6,272\n",
            "│    └─LeakyReLU: 2-2                    [3, 128, 32, 32]          --\n",
            "│    └─Conv2d: 2-3                       [3, 256, 16, 16]          524,544\n",
            "│    └─BatchNorm2d: 2-4                  [3, 256, 16, 16]          512\n",
            "│    └─LeakyReLU: 2-5                    [3, 256, 16, 16]          --\n",
            "│    └─Conv2d: 2-6                       [3, 512, 8, 8]            2,097,664\n",
            "│    └─BatchNorm2d: 2-7                  [3, 512, 8, 8]            1,024\n",
            "│    └─LeakyReLU: 2-8                    [3, 512, 8, 8]            --\n",
            "├─Sequential: 1-2                        [3, 1]                    --\n",
            "│    └─Rearrange: 2-9                    [3, 32768]                --\n",
            "│    └─Linear: 2-10                      [3, 1]                    32,768\n",
            "==========================================================================================\n",
            "Total params: 2,662,784\n",
            "Trainable params: 2,662,784\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 824.97\n",
            "==========================================================================================\n",
            "Input size (MB): 0.15\n",
            "Forward/backward pass size (MB): 7.86\n",
            "Params size (MB): 10.65\n",
            "Estimated Total Size (MB): 18.66\n",
            "==========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DCGANArgs:\n",
        "    \"\"\"\n",
        "    Class for the arguments to the DCGAN (training and architecture).\n",
        "    Note, we use field(defaultfactory(...)) when our default value is a mutable object.\n",
        "    \"\"\"\n",
        "\n",
        "    # architecture\n",
        "    latent_dim_size: int = 100\n",
        "    hidden_channels: list[int] = field(default_factory=lambda: [128, 256, 512])\n",
        "\n",
        "    # data & training\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 3\n",
        "    lr: float = 0.0002\n",
        "    betas: tuple[float, float] = (0.5, 0.999)\n",
        "    clip_grad_norm: float | None = None\n",
        "\n",
        "    # logging\n",
        "    use_wandb: bool = True\n",
        "    wandb_project: str | None = \"day5-gan\"\n",
        "    wandb_name: str | None = None\n",
        "    log_every_n_steps: int = 250\n",
        "\n",
        "\n",
        "class DCGANTrainer:\n",
        "    def __init__(self, args: DCGANArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset()\n",
        "        self.trainloader = DataLoader(\n",
        "            self.trainset, batch_size=args.batch_size, shuffle=True, num_workers=8\n",
        "        )\n",
        "\n",
        "        batch, img_channels, img_height, img_width = next(iter(self.trainloader))[0].shape\n",
        "        assert img_height == img_width\n",
        "\n",
        "        self.model = (\n",
        "            DCGAN(args.latent_dim_size, img_height, img_channels, args.hidden_channels)\n",
        "            .to(device)\n",
        "            .train()\n",
        "        )\n",
        "\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        self.optG = t.optim.Adam(self.model.netG.parameters(), lr=args.lr, betas=args.betas)\n",
        "        self.optD = t.optim.Adam(self.model.netD.parameters(), lr=args.lr, betas=args.betas)\n",
        "\n",
        "    def training_step_discriminator(\n",
        "        self,\n",
        "        img_real: Float[Tensor, \"batch channels height width\"],\n",
        "        img_fake: Float[Tensor, \"batch channels height width\"],\n",
        "    ) -> Float[Tensor, \"\"]:\n",
        "        \"\"\"\n",
        "        Generates a real and fake image, and performs a gradient step on the discriminator to\n",
        "        maximize log(D(x)) + log(1-D(G(z))). Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        self.optD.zero_grad()\n",
        "\n",
        "        d_g_z = self.model.netD(img_fake.detach())\n",
        "        labels_zeros = t.zeros_like(d_g_z)\n",
        "        loss_fake = self.loss_fn(d_g_z, labels_zeros) # -log(1 - d_g_z)\n",
        "\n",
        "        d_x = self.model.netD(img_real)\n",
        "        labels_ones = t.ones_like(d_x)\n",
        "        loss_real = self.loss_fn(d_x, labels_ones) # -log(d_x)\n",
        "\n",
        "        loss = loss_fake + loss_real\n",
        "\n",
        "        loss.backward()\n",
        "        if self.args.clip_grad_norm is not None:\n",
        "          nn.utils.clip_grad_norm_(self.model.netD.parameters(), self.args.clip_grad_norm)\n",
        "        self.optD.step()\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log(dict(lossD=loss), step=self.step)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step_generator(\n",
        "        self, img_fake: Float[Tensor, \"batch channels height width\"]\n",
        "    ) -> Float[Tensor, \"\"]:\n",
        "        \"\"\"\n",
        "        Performs a gradient step on the generator to maximize log(D(G(z))). Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        self.optG.zero_grad()\n",
        "\n",
        "        d_g_z = self.model.netD(img_fake)\n",
        "        labels_ones = t.ones_like(d_g_z)\n",
        "        loss = self.loss_fn(d_g_z, labels_ones) # non saturating version - min log(D(G(z)))\n",
        "\n",
        "        loss.backward()\n",
        "        if self.args.clip_grad_norm is not None:\n",
        "          nn.utils.clip_grad_norm_(self.model.netG.parameters(), self.args.clip_grad_norm)\n",
        "        self.optG.step()\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log(dict(lossG=loss), step=self.step)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Performs evaluation by generating 8 instances of random noise and passing them through the\n",
        "        generator, then optionally logging the results to Weights & Biases.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, (\n",
        "            \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        )\n",
        "        self.model.netG.eval()\n",
        "\n",
        "        # Generate random noise\n",
        "        t.manual_seed(42)\n",
        "        noise = t.randn(10, self.model.latent_dim_size).to(device)\n",
        "        # Get generator output\n",
        "        output = self.model.netG(noise)\n",
        "        # Clip values to make the visualization clearer\n",
        "        output = output.clamp(output.quantile(0.01), output.quantile(0.99))\n",
        "        # Log to weights and biases\n",
        "        if self.args.use_wandb:\n",
        "            output = einops.rearrange(output, \"b c h w -> b h w c\").cpu().numpy()\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output]}, step=self.step)\n",
        "\n",
        "        self.model.netG.train()\n",
        "\n",
        "    def train(self) -> DCGAN:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            progress_bar = tqdm(self.trainloader, total=len(self.trainloader), ascii=True)\n",
        "\n",
        "            for img_real, label in progress_bar:\n",
        "                img_real = img_real.to(device)\n",
        "                z = t.randn(self.args.batch_size, self.model.latent_dim_size).to(device)\n",
        "                img_fake = self.model.netG(z)\n",
        "                lossD = self.training_step_discriminator(img_real, img_fake.detach())\n",
        "\n",
        "                lossG = self.training_step_generator(img_fake)\n",
        "\n",
        "                self.step += 1\n",
        "                progress_bar.set_description(f\"{epoch=}, {lossD=:.4f}, {lossG=:.4f}, batches={self.step}\")\n",
        "\n",
        "                if self.step % self.args.log_every_n_steps == 0:\n",
        "                    self.log_samples()\n",
        "\n",
        "            gen_path, disc_path = self.save_checkpoint(epoch)\n",
        "\n",
        "            if self.args.use_wandb:\n",
        "                self.log_artifact(gen_path, disc_path, epoch)\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def save_checkpoint(self, epoch: int):\n",
        "      os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "      gen_path = f\"checkpoints/generator_epoch{epoch}.pt\"\n",
        "      disc_path = f\"checkpoints/discriminator_epoch{epoch}.pt\"\n",
        "\n",
        "      t.save(self.model.netG.state_dict(), gen_path)\n",
        "      t.save(self.model.netD.state_dict(), disc_path)\n",
        "\n",
        "      return gen_path, disc_path\n",
        "\n",
        "    def log_artifact(self, gen_path: str, disc_path: str, epoch: int):\n",
        "      artifact = wandb.Artifact(f\"dcgan_epoch_{epoch}\", type=\"model\")\n",
        "      artifact.add_file(gen_path)\n",
        "      artifact.add_file(disc_path)\n",
        "      wandb.log_artifact(artifact)\n",
        "\n"
      ],
      "metadata": {
        "id": "KZTLzgvdESkp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arguments for CelebA\n",
        "args = DCGANArgs(\n",
        "    hidden_channels=[128, 256, 512],\n",
        "    batch_size=32,  # if you get OOM errors, reduce this!\n",
        "    epochs=5,\n",
        "    use_wandb=True,\n",
        ")\n",
        "trainer = DCGANTrainer(args)\n",
        "# dcgan = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCzsMNsdEfTu",
        "outputId": "a5bd3f17-f604-487b-da70-ed5c3f2ba82e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\n",
            "From (redirected): https://drive.usercontent.google.com/download?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM&confirm=t&uuid=a010d80a-8361-46c6-8451-f76a1a018116\n",
            "To: /content/data/celeba/img_align_celeba.zip\n",
            "\n",
            "  0%|          | 0.00/1.44G [00:00<?, ?B/s]\u001b[A\n",
            "  0%|          | 1.57M/1.44G [00:00<04:24, 5.45MB/s]\u001b[A\n",
            "  0%|          | 2.62M/1.44G [00:00<03:23, 7.09MB/s]\u001b[A\n",
            "  1%|          | 7.34M/1.44G [00:00<01:22, 17.5MB/s]\u001b[A\n",
            "  1%|          | 9.44M/1.44G [00:00<01:28, 16.2MB/s]\u001b[A\n",
            "  2%|▏         | 30.4M/1.44G [00:01<00:37, 37.9MB/s]\u001b[A\n",
            "  4%|▎         | 53.5M/1.44G [00:01<00:19, 71.5MB/s]\u001b[A\n",
            "  4%|▍         | 63.4M/1.44G [00:01<00:29, 47.4MB/s]\u001b[A\n",
            "  6%|▌         | 80.7M/1.44G [00:01<00:28, 47.8MB/s]\u001b[A\n",
            "  7%|▋         | 101M/1.44G [00:02<00:22, 60.1MB/s] \u001b[A\n",
            "  8%|▊         | 114M/1.44G [00:02<00:20, 64.0MB/s]\u001b[A\n",
            "  8%|▊         | 122M/1.44G [00:02<00:21, 62.5MB/s]\u001b[A\n",
            " 10%|▉         | 143M/1.44G [00:02<00:15, 82.0MB/s]\u001b[A\n",
            " 11%|█         | 153M/1.44G [00:02<00:18, 70.0MB/s]\u001b[A\n",
            " 12%|█▏        | 173M/1.44G [00:02<00:14, 87.7MB/s]\u001b[A\n",
            " 13%|█▎        | 183M/1.44G [00:03<00:19, 66.3MB/s]\u001b[A\n",
            " 14%|█▍        | 208M/1.44G [00:03<00:13, 92.4MB/s]\u001b[A\n",
            " 15%|█▌        | 219M/1.44G [00:03<00:17, 70.6MB/s]\u001b[A\n",
            " 17%|█▋        | 239M/1.44G [00:04<00:19, 62.7MB/s]\u001b[A\n",
            " 18%|█▊        | 260M/1.44G [00:04<00:14, 83.0MB/s]\u001b[A\n",
            " 19%|█▉        | 272M/1.44G [00:04<00:13, 84.9MB/s]\u001b[A\n",
            " 20%|█▉        | 284M/1.44G [00:04<00:26, 44.1MB/s]\u001b[A\n",
            " 21%|██        | 305M/1.44G [00:05<00:18, 62.6MB/s]\u001b[A\n",
            " 22%|██▏       | 317M/1.44G [00:05<00:18, 60.7MB/s]\u001b[A\n",
            " 23%|██▎       | 332M/1.44G [00:05<00:14, 74.3MB/s]\u001b[A\n",
            " 24%|██▍       | 344M/1.44G [00:05<00:16, 66.1MB/s]\u001b[A\n",
            " 25%|██▍       | 355M/1.44G [00:05<00:15, 71.7MB/s]\u001b[A\n",
            " 26%|██▌       | 376M/1.44G [00:05<00:11, 95.8MB/s]\u001b[A\n",
            " 27%|██▋       | 389M/1.44G [00:06<00:12, 85.3MB/s]\u001b[A\n",
            " 28%|██▊       | 402M/1.44G [00:06<00:11, 92.9MB/s]\u001b[A\n",
            " 29%|██▉       | 417M/1.44G [00:06<00:10, 95.8MB/s]\u001b[A\n",
            " 30%|██▉       | 428M/1.44G [00:06<00:11, 91.9MB/s]\u001b[A\n",
            " 31%|███       | 442M/1.44G [00:06<00:10, 93.5MB/s]\u001b[A\n",
            " 32%|███▏      | 458M/1.44G [00:06<00:09, 102MB/s] \u001b[A\n",
            " 33%|███▎      | 475M/1.44G [00:06<00:08, 113MB/s]\u001b[A\n",
            " 34%|███▎      | 487M/1.44G [00:06<00:09, 102MB/s]\u001b[A\n",
            " 35%|███▍      | 498M/1.44G [00:07<00:09, 102MB/s]\u001b[A\n",
            " 36%|███▌      | 519M/1.44G [00:07<00:07, 125MB/s]\u001b[A\n",
            " 37%|███▋      | 532M/1.44G [00:07<00:08, 106MB/s]\u001b[A\n",
            " 38%|███▊      | 543M/1.44G [00:07<00:09, 98.9MB/s]\u001b[A\n",
            " 39%|███▉      | 562M/1.44G [00:07<00:07, 120MB/s] \u001b[A\n",
            " 40%|███▉      | 575M/1.44G [00:07<00:08, 101MB/s]\u001b[A\n",
            " 41%|████      | 587M/1.44G [00:07<00:09, 90.2MB/s]\u001b[A\n",
            " 42%|████▏     | 602M/1.44G [00:08<00:08, 105MB/s] \u001b[A\n",
            " 43%|████▎     | 617M/1.44G [00:08<00:10, 82.5MB/s]\u001b[A\n",
            " 44%|████▍     | 633M/1.44G [00:08<00:08, 90.3MB/s]\u001b[A\n",
            " 45%|████▌     | 653M/1.44G [00:08<00:08, 91.2MB/s]\u001b[A\n",
            " 46%|████▋     | 668M/1.44G [00:08<00:08, 94.2MB/s]\u001b[A\n",
            " 47%|████▋     | 684M/1.44G [00:08<00:07, 107MB/s] \u001b[A\n",
            " 48%|████▊     | 697M/1.44G [00:09<00:06, 112MB/s]\u001b[A\n",
            " 49%|████▉     | 710M/1.44G [00:09<00:07, 101MB/s]\u001b[A\n",
            " 50%|████▉     | 721M/1.44G [00:09<00:08, 83.2MB/s]\u001b[A\n",
            " 52%|█████▏    | 743M/1.44G [00:09<00:06, 113MB/s] \u001b[A\n",
            " 52%|█████▏    | 757M/1.44G [00:09<00:08, 82.1MB/s]\u001b[A\n",
            " 54%|█████▍    | 780M/1.44G [00:09<00:06, 108MB/s] \u001b[A\n",
            " 55%|█████▍    | 794M/1.44G [00:10<00:08, 81.1MB/s]\u001b[A\n",
            " 56%|█████▌    | 812M/1.44G [00:10<00:06, 91.2MB/s]\u001b[A\n",
            " 57%|█████▋    | 825M/1.44G [00:10<00:06, 97.6MB/s]\u001b[A\n",
            " 58%|█████▊    | 837M/1.44G [00:10<00:06, 94.1MB/s]\u001b[A\n",
            " 59%|█████▊    | 848M/1.44G [00:10<00:06, 90.2MB/s]\u001b[A\n",
            " 60%|█████▉    | 864M/1.44G [00:10<00:05, 99.0MB/s]\u001b[A\n",
            " 61%|██████    | 880M/1.44G [00:10<00:05, 104MB/s] \u001b[A\n",
            " 62%|██████▏   | 891M/1.44G [00:11<00:05, 98.5MB/s]\u001b[A\n",
            " 63%|██████▎   | 908M/1.44G [00:11<00:08, 61.1MB/s]\u001b[A\n",
            " 64%|██████▍   | 927M/1.44G [00:11<00:06, 81.2MB/s]\u001b[A\n",
            " 65%|██████▌   | 944M/1.44G [00:11<00:05, 89.0MB/s]\u001b[A\n",
            " 66%|██████▌   | 956M/1.44G [00:11<00:05, 89.4MB/s]\u001b[A\n",
            " 67%|██████▋   | 967M/1.44G [00:12<00:06, 73.9MB/s]\u001b[A\n",
            " 68%|██████▊   | 988M/1.44G [00:12<00:04, 99.4MB/s]\u001b[A\n",
            " 69%|██████▉   | 1.00G/1.44G [00:12<00:05, 87.9MB/s]\u001b[A\n",
            " 71%|███████   | 1.02G/1.44G [00:12<00:04, 95.2MB/s]\u001b[A\n",
            " 72%|███████▏  | 1.04G/1.44G [00:12<00:04, 99.7MB/s]\u001b[A\n",
            " 73%|███████▎  | 1.05G/1.44G [00:12<00:03, 109MB/s] \u001b[A\n",
            " 74%|███████▎  | 1.06G/1.44G [00:13<00:03, 106MB/s]\u001b[A\n",
            " 74%|███████▍  | 1.07G/1.44G [00:13<00:07, 49.0MB/s]\u001b[A\n",
            " 75%|███████▌  | 1.08G/1.44G [00:13<00:06, 53.2MB/s]\u001b[A\n",
            " 77%|███████▋  | 1.11G/1.44G [00:13<00:04, 78.4MB/s]\u001b[A\n",
            " 77%|███████▋  | 1.12G/1.44G [00:14<00:04, 75.7MB/s]\u001b[A\n",
            " 79%|███████▊  | 1.13G/1.44G [00:14<00:03, 85.0MB/s]\u001b[A\n",
            " 79%|███████▉  | 1.14G/1.44G [00:14<00:03, 83.8MB/s]\u001b[A\n",
            " 81%|████████  | 1.16G/1.44G [00:14<00:02, 105MB/s] \u001b[A\n",
            " 81%|████████▏ | 1.18G/1.44G [00:14<00:03, 86.0MB/s]\u001b[A\n",
            " 82%|████████▏ | 1.19G/1.44G [00:14<00:02, 92.0MB/s]\u001b[A\n",
            " 83%|████████▎ | 1.20G/1.44G [00:14<00:02, 88.7MB/s]\u001b[A\n",
            " 84%|████████▍ | 1.21G/1.44G [00:14<00:02, 94.4MB/s]\u001b[A\n",
            " 85%|████████▌ | 1.23G/1.44G [00:15<00:01, 116MB/s] \u001b[A\n",
            " 86%|████████▌ | 1.24G/1.44G [00:15<00:01, 106MB/s]\u001b[A\n",
            " 87%|████████▋ | 1.25G/1.44G [00:15<00:02, 92.5MB/s]\u001b[A\n",
            " 88%|████████▊ | 1.27G/1.44G [00:15<00:01, 101MB/s] \u001b[A\n",
            " 89%|████████▉ | 1.28G/1.44G [00:15<00:01, 100MB/s]\u001b[A\n",
            " 90%|████████▉ | 1.30G/1.44G [00:15<00:01, 115MB/s]\u001b[A\n",
            " 91%|█████████ | 1.31G/1.44G [00:15<00:01, 114MB/s]\u001b[A\n",
            " 92%|█████████▏| 1.32G/1.44G [00:16<00:01, 97.9MB/s]\u001b[A\n",
            " 92%|█████████▏| 1.33G/1.44G [00:16<00:01, 74.9MB/s]\u001b[A\n",
            " 94%|█████████▍| 1.36G/1.44G [00:16<00:00, 102MB/s] \u001b[A\n",
            " 95%|█████████▌| 1.37G/1.44G [00:16<00:00, 116MB/s]\u001b[A\n",
            " 96%|█████████▌| 1.39G/1.44G [00:16<00:00, 89.4MB/s]\u001b[A\n",
            " 97%|█████████▋| 1.40G/1.44G [00:16<00:00, 92.9MB/s]\u001b[A\n",
            " 98%|█████████▊| 1.41G/1.44G [00:16<00:00, 97.8MB/s]\u001b[A\n",
            " 98%|█████████▊| 1.42G/1.44G [00:17<00:00, 83.6MB/s]\u001b[A\n",
            "100%|██████████| 1.44G/1.44G [00:17<00:00, 83.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pblRyaVFSWGxPY0U\n",
            "To: /content/data/celeba/list_attr_celeba.txt\n",
            "\n",
            "  0%|          | 0.00/26.7M [00:00<?, ?B/s]\u001b[A\n",
            "100%|██████████| 26.7M/26.7M [00:00<00:00, 153MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_ee_0u7vcNLOfNLegJRHmolfH5ICW-XS\n",
            "To: /content/data/celeba/identity_CelebA.txt\n",
            "\n",
            "100%|██████████| 3.42M/3.42M [00:00<00:00, 167MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pbThiMVRxWXZ4dU0\n",
            "To: /content/data/celeba/list_bbox_celeba.txt\n",
            "\n",
            "  0%|          | 0.00/6.08M [00:00<?, ?B/s]\u001b[A\n",
            "100%|██████████| 6.08M/6.08M [00:00<00:00, 21.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pd0FJY3Blby1HUTQ\n",
            "To: /content/data/celeba/list_landmarks_align_celeba.txt\n",
            "\n",
            "100%|██████████| 12.2M/12.2M [00:00<00:00, 192MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pY0NSMzRuSXJEVkk\n",
            "To: /content/data/celeba/list_eval_partition.txt\n",
            "\n",
            "100%|██████████| 2.84M/2.84M [00:00<00:00, 242MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = DCGANArgs(\n",
        "    hidden_channels=[128, 256, 512],\n",
        "    batch_size=32,\n",
        "    epochs=5,\n",
        "    use_wandb=False,\n",
        ")\n",
        "model = DCGAN(args)\n",
        "model.netG.load_state_dict(t.load(\"checkpoints/generator_epoch2.pt\"))"
      ],
      "metadata": {
        "id": "i1Jyu7M1EhX1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}